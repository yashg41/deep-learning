{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "defe4dff",
   "metadata": {},
   "source": [
    "# KNEE BEND DETECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecfed76",
   "metadata": {},
   "source": [
    "libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "627d834a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176c48a7",
   "metadata": {},
   "source": [
    "INITIIALISATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e52e50a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize mediapipe pose class.\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "# Setup the Pose function for videos - for video processing.\n",
    "pose_video = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.7,\n",
    "                          min_tracking_confidence=0.7)\n",
    "\n",
    "# Initialize mediapipe drawing class - to draw the landmarks points.\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3a3cdd",
   "metadata": {},
   "source": [
    "RUNNING OF THE INPUT VIDEO AND OUTPUTING ITS CORRESPONDING GRAYSCALE VIDEO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cb1d0432",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    " \n",
    "# Creating a VideoCapture object to read the video\n",
    "cap = cv2.VideoCapture('KneeBendVideo.mp4')\n",
    " \n",
    " \n",
    "# Loop until the end of the video\n",
    "while (cap.isOpened()):\n",
    " \n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.resize(frame, (540, 380), fx = 0, fy = 0,\n",
    "                         interpolation = cv2.INTER_CUBIC)\n",
    " \n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Frame', frame)\n",
    " \n",
    "    # conversion of BGR to grayscale is necessary to apply this operation\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    " \n",
    "    # adaptive thresholding to use different threshold\n",
    "    # values on different regions of the frame.\n",
    "    Thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "                                           cv2.THRESH_BINARY_INV, 11, 2)\n",
    " \n",
    "    cv2.imshow('Thresh', Thresh)\n",
    "    # define q as the exit button\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    " \n",
    "# release the video capture object\n",
    "cap.release()\n",
    "# Closes all the windows currently opened.\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2775297",
   "metadata": {},
   "source": [
    "EXTRACTING LANDMARKS AND RENDERING DETECTION ON THE INPUT VIDEO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e7d84041",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('KneeBendVideo.mp4')\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor image to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "      \n",
    "        # Make detection\n",
    "        results = pose.process(image)\n",
    "    \n",
    "        # Recolor back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "         # Extract landmarks\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Render detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2), \n",
    "                                mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2) \n",
    "                                 )               \n",
    "        \n",
    "        cv2.imshow('Mediapipe Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d99d92",
   "metadata": {},
   "source": [
    "LIST OF LANDMARKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b0cefe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PoseLandmark.NOSE\n",
      "PoseLandmark.LEFT_EYE_INNER\n",
      "PoseLandmark.LEFT_EYE\n",
      "PoseLandmark.LEFT_EYE_OUTER\n",
      "PoseLandmark.RIGHT_EYE_INNER\n",
      "PoseLandmark.RIGHT_EYE\n",
      "PoseLandmark.RIGHT_EYE_OUTER\n",
      "PoseLandmark.LEFT_EAR\n",
      "PoseLandmark.RIGHT_EAR\n",
      "PoseLandmark.MOUTH_LEFT\n",
      "PoseLandmark.MOUTH_RIGHT\n",
      "PoseLandmark.LEFT_SHOULDER\n",
      "PoseLandmark.RIGHT_SHOULDER\n",
      "PoseLandmark.LEFT_ELBOW\n",
      "PoseLandmark.RIGHT_ELBOW\n",
      "PoseLandmark.LEFT_WRIST\n",
      "PoseLandmark.RIGHT_WRIST\n",
      "PoseLandmark.LEFT_PINKY\n",
      "PoseLandmark.RIGHT_PINKY\n",
      "PoseLandmark.LEFT_INDEX\n",
      "PoseLandmark.RIGHT_INDEX\n",
      "PoseLandmark.LEFT_THUMB\n",
      "PoseLandmark.RIGHT_THUMB\n",
      "PoseLandmark.LEFT_HIP\n",
      "PoseLandmark.RIGHT_HIP\n",
      "PoseLandmark.LEFT_KNEE\n",
      "PoseLandmark.RIGHT_KNEE\n",
      "PoseLandmark.LEFT_ANKLE\n",
      "PoseLandmark.RIGHT_ANKLE\n",
      "PoseLandmark.LEFT_HEEL\n",
      "PoseLandmark.RIGHT_HEEL\n",
      "PoseLandmark.LEFT_FOOT_INDEX\n",
      "PoseLandmark.RIGHT_FOOT_INDEX\n"
     ]
    }
   ],
   "source": [
    "for lndmrk in mp_pose.PoseLandmark:\n",
    "    print(lndmrk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65926760",
   "metadata": {},
   "source": [
    "CALCULATING ANGLE AT WHICH KNEE IS BENDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e630395",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angle(a,b,c):\n",
    "    a = np.array(a) # First\n",
    "    b = np.array(b) # Mid\n",
    "    c = np.array(c) # End\n",
    "    \n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "    angle = np.abs(radians*180.0/np.pi)\n",
    "    \n",
    "    if angle >180.0:\n",
    "        angle = 360-angle\n",
    "        \n",
    "    return angle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c185f574",
   "metadata": {},
   "outputs": [],
   "source": [
    "HIP = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "KNEE = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x,landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "ANKLE = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c0b041e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.6427669525146484, 0.8210180997848511],\n",
       " [0.4515906870365143, 0.8259276151657104],\n",
       " [0.34357646107673645, 0.8653447031974792])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HIP,KNEE,ANKLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3070029a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161.42277644328422"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_angle(HIP,KNEE, ANKLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9653535",
   "metadata": {},
   "source": [
    "VISUALISING ANGLE ON THE INPUT VIDEO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5ef31a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('KneeBendVideo.mp4')\n",
    "## Setup mediapipe instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor image to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "      \n",
    "        # Make detection\n",
    "        results = pose.process(image)\n",
    "    \n",
    "        # Recolor back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Extract landmarks\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # Get coordinates\n",
    "            HIPL = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "            KNEEL = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x,landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "            ANKLEL = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]\n",
    "\n",
    "            # Calculate angle\n",
    "            angle = calculate_angle(HIPL,KNEEL, ANKLEL)\n",
    "            \n",
    "            # Visualize angle\n",
    "            cv2.putText(image, str(angle), \n",
    "                           tuple(np.multiply(KNEEL, [854 ,640]).astype(int)), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA\n",
    "                                )\n",
    "            \n",
    "            HIPR = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "            KNEER = [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].y]\n",
    "            ANKLER = [landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y]\n",
    "\n",
    "            # Calculate angle\n",
    "            angle = calculate_angle(HIPR,KNEER, ANKLER)\n",
    "            \n",
    "            # Visualize angle\n",
    "            cv2.putText(image, str(angle), \n",
    "                           tuple(np.multiply(KNEER, [854 ,640]).astype(int)), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA\n",
    "                                )\n",
    "                       \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        # Render detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2), \n",
    "                                mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2) \n",
    "                                 )               \n",
    "        \n",
    "        cv2.imshow('Mediapipe Feed', image)\n",
    "       \n",
    "        \n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cd13b9f5",
   "metadata": {},
   "source": [
    "FULFILLING TASK CONDITIONS:\n",
    "    1)STAGE=KNEE BENT when Angle<140 degrees\n",
    "    2)Checking the form for 8 secs\n",
    "    3)outputting \"knee not bent\" in case of failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "484d9a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keep knees bend\n",
      "keep knees bend\n",
      "keep knees bend\n",
      "keep knees bend\n",
      "keep knees bend\n",
      "keep knees bend\n",
      "keep knees bend\n",
      "keep knees bend\n",
      "keep knees bend\n",
      "keep knees bend\n",
      "keep knees bend\n",
      "keep knees bend\n",
      "keep knees bend\n",
      "keep knees bend\n",
      "keep knees bend\n",
      "keep knees bend\n",
      "keep knees bend\n",
      "keep knees bend\n",
      "keep knees bend\n",
      "keep knees bend\n",
      "keep knees bend\n",
      "keep knees bend\n",
      "keep knees bend\n",
      "keep knees bend\n",
      "keep knees bend\n",
      "keep knees bend\n",
      "keep knees bend\n",
      "keep knees bend\n",
      "keep knees bend\n",
      "keep knees bend\n",
      "keep knees bend\n",
      "keep knees bend\n",
      "keep knees bend\n",
      "keep knees bend\n",
      "keep knees bend\n",
      "keep knees bend\n",
      "keep knees bend\n",
      "keep knees bend\n",
      "keep knees bend\n",
      "keep knees bend\n",
      "keep knees bend\n",
      "keep knees bend\n",
      "keep knees bend\n",
      "keep knees bend\n",
      "keep knees bend\n",
      "keep knees bend\n",
      "keep knees bend\n",
      "keep knees bend\n",
      "keep knees bend\n",
      "keep knees bend\n",
      "keep knees bend\n",
      "keep knees bend\n",
      "keep knees bend\n",
      "keep knees bend\n",
      "keep knees bend\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('KneeBendVideo.mp4')\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "# Bend variables\n",
    "stage = None\n",
    "\n",
    "## Setup mediapipe instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor image to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "      \n",
    "        # Make detection\n",
    "        results = pose.process(image)\n",
    "    \n",
    "        # Recolor back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Extract landmarks\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # Get coordinates left\n",
    "            HIPL = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "            KNEEL = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x,landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "            ANKLEL = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]\n",
    "\n",
    "            # Calculate angle\n",
    "            angle1 = calculate_angle(HIPL,KNEEL, ANKLEL)\n",
    "            \n",
    "            # Visualize angle\n",
    "            cv2.putText(image, str(angle1), \n",
    "                           tuple(np.multiply(KNEEL, [854 ,640]).astype(int)), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA\n",
    "                                )\n",
    "            \n",
    "            # Get coordinates RIGHT\n",
    "            HIPR = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "            KNEER = [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].y]\n",
    "            ANKLER = [landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y]\n",
    "\n",
    "            # Calculate angle\n",
    "            angle2 = calculate_angle(HIPR,KNEER, ANKLER)\n",
    "            \n",
    "            # Visualize angle\n",
    "            cv2.putText(image, str(angle2), \n",
    "                           tuple(np.multiply(KNEER, [854 ,640]).astype(int)), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA\n",
    "                                )\n",
    "            \n",
    "            # Bend logic\n",
    "          \n",
    "            if angle1 < 140:\n",
    "                stage = \"bend\"\n",
    "                bad_frames = 0\n",
    "                good_frames += 1\n",
    "\n",
    "\n",
    "            if angle1 > 140:\n",
    "                stage=\"not bend\"\n",
    "                good_frames = 0\n",
    "                bad_frames += 1\n",
    "               \n",
    "           # Calculate the time of remaining in a particular posture.\n",
    "            good_time = (1 / fps) * good_frames\n",
    "\n",
    "            bad_time =  (1 / fps) * bad_frames\n",
    " \n",
    "            if good_time<8 and stage=='not bend':\n",
    "                print(\"keep knees bend\")\n",
    "                cv2.putText(image, 'keep knees bend', (150,120), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 2, (0,0,0), 2, cv2.LINE_AA)\n",
    "            \n",
    "            if good_time>8 and stage=='bend':\n",
    "                    print(\"u can relax now\")\n",
    "                    cv2.putText(image, 'u can relax now', (150,120), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 2, (0,0,0), 2, cv2.LINE_AA)\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Setup status box\n",
    "        cv2.rectangle(image, (0,0), (400,73), (245,117,16), -1)\n",
    "        \n",
    "        # Rep data\n",
    "        cv2.putText(image, 'REPS STAGE', (15,12), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)\n",
    "#         cv2.putText(image, str(counter), \n",
    "#                     (10,60), \n",
    "#                     cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), 2, cv2.LINE_AA)\n",
    "        \n",
    "        # Stage data\n",
    "        cv2.putText(image, stage, \n",
    "                    (15,60), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), 2, cv2.LINE_AA)\n",
    "        \n",
    "        \n",
    "        # Render detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2), \n",
    "                                mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2) \n",
    "                                 )               \n",
    "        \n",
    "        cv2.imshow('Mediapipe Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fcaf92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
